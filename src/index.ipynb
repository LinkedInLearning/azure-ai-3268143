{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détecter la langue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** : Créez une ressource *Analytique de texte* ou *Text analytics* et renseignez `SERVEUR` avec votre point de terminaison (endpoint). Récupérez également la clé et renseignez là lors de l'exécution de la première cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "CLE = getpass(\"Clé\")\n",
    "SERVEUR = 'https://textanalysis00.cognitiveservices.azure.com/'  # Votre point de terminaison\n",
    "\n",
    "TEXTE = \"\"\"\n",
    "    'To be or not to be' disait Shakespeare \n",
    "    mais ce texte est dans la langue de Molière, \n",
    "    même s'il contient quelques anglicismes comme business workflow \n",
    "    ou une faute d'orthographe dans connection.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sans SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'id': '1',\n",
       "   'detectedLanguages': [{'name': 'French',\n",
       "     'iso6391Name': 'fr',\n",
       "     'score': 1.0}]}],\n",
       " 'errors': []}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "reponse = requests.post(\n",
    "  url = SERVEUR + '/text/analytics/v2.1/languages',\n",
    "  headers = {'Ocp-Apim-Subscription-Key': CLE},\n",
    "  json = {'documents': [{'id': '1', 'text': TEXTE}]}\n",
    ")\n",
    "reponse.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-language-textanalytics\n",
      "  Downloading azure_cognitiveservices_language_textanalytics-0.2.1-py2.py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting msrest>=0.6.21 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-common~=1.1 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting azure-core<2.0.0,>=1.26.2 (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_core-1.27.1-py3-none-any.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2023.5.7)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in /home/codespace/.local/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.0.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: azure-common, oauthlib, isodate, requests-oauthlib, azure-core, msrest, azure-mgmt-core, azure-cognitiveservices-language-textanalytics\n",
      "Successfully installed azure-cognitiveservices-language-textanalytics-0.2.1 azure-common-1.1.28 azure-core-1.27.1 azure-mgmt-core-1.4.0 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-language-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiTexte = TextAnalyticsClient(SERVEUR, CognitiveServicesCredentials(CLE))\n",
    "\n",
    "reponse = apiTexte.detect_language(documents=[{ 'id':'1', 'text': TEXTE}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'additional_properties': {},\n",
      "  'iso6391_name': 'fr',\n",
      "  'name': 'French',\n",
      "  'score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "pprint([langue.__dict__ for langue in reponse.documents[0].detected_languages])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
