{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyser du texte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** : Créez une ressource *Analytique de texte* ou *Text analytics* et renseignez `SERVEUR` avec votre point de terminaison (endpoint). Récupérez également la clé et renseignez là lors de l'exécution de la première cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "CLE = getpass(\"Clé\")\n",
    "SERVEUR = 'https://textanalysis00.cognitiveservices.azure.com/'  # Votre point de terminaison\n",
    "\n",
    "TEXTE1 = \"\"\"\n",
    "    Passepartout, les mains dans les poches, se rendit donc vers le port Victoria, \n",
    "    regardant les palanquins, les brouettes à voile, encore en faveur dans \n",
    "    le Céleste Empire, et toute cette foule de Chinois, de Japonais et \n",
    "    d’Européens, qui se pressait dans les rues.\n",
    "\"\"\"\n",
    "# Jules Verne, Le tour du monde en qutre-vingt jours, Chapitre XIX\n",
    "\n",
    "TEXTE2 = \"\"\"\n",
    "    SATURDAY morning was come, and all the summer world was bright and fresh,\n",
    "    and brimming with life. There was a song in every heart; and if the heart \n",
    "    was young the music issued at the lips. There was cheer in every face and \n",
    "    a spring in every step. The locust-trees were in bloom and the fragrance \n",
    "    of the blossoms filled the air.\n",
    "\"\"\"\n",
    "# Mark Twain, The Adventures of Tom Sawyer, Chapter II\n",
    "\n",
    "TEXTE3 = \"\"\"\n",
    "    Deja á la luna verme con luz tranquila y suave;\n",
    "    Deja que el alba envíe su resplandor fugaz,\n",
    "    Deja gemir al viento con su murmullo grave,\n",
    "    Y si desciende y posa sobre mi cruz un ave\n",
    "    Deja que el ave entone su cantico de paz.\n",
    "\"\"\"\n",
    "# Jose Rizal, Mi Ultimo Adiós\n",
    "\n",
    "TEXTE4 = \"\"\"\n",
    "    Hélas ! Combien de temps faudra-t-il vous redire\n",
    "    À vous tous, que c'était à vous de les conduire,\n",
    "    Qu'il fallait leur donner leur part de la cité,\n",
    "    Que votre aveuglement produit leur cécité ;\n",
    "    D'une tutelle avare on recueille les suites,\n",
    "    Et le mal qu'ils vous font, c'est vous qui le leur fîtes.\n",
    "    Vous ne les avez pas guidés, pris par la main,\n",
    "    Et renseignés sur l'ombre et sur le vrai chemin ;\n",
    "    Vous les avez laissés en proie au labyrinthe.\n",
    "    Ils sont votre épouvante et vous êtes leur crainte ;\n",
    "\"\"\"\n",
    "# Victor Hugo, L'année terrible, Poésie XII"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sans SDK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "reponse = requests.post(\n",
    "    url=SERVEUR + '/text/analytics/v2.1/sentiment',\n",
    "    headers={'Ocp-Apim-Subscription-Key': CLE},\n",
    "    json={'documents': [\n",
    "        {'id': '1', 'language': 'fr', 'text': TEXTE1},\n",
    "        {'id': '2', 'language': 'en', 'text': TEXTE2},\n",
    "        {'id': '3', 'language': 'es', 'text': TEXTE3},\n",
    "        {'id': '4', 'language': 'fr', 'text': TEXTE4}\n",
    "    ]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '2', 'score': 0.9599582552909851},\n",
      " {'id': '1', 'score': 0.7140833735466003},\n",
      " {'id': '3', 'score': 0.6403309106826782},\n",
      " {'id': '4', 'score': 0.3863636255264282}]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(reponse.json()['documents'], key=lambda doc: -doc['score']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "reponse = requests.post(\n",
    "    url=SERVEUR + '/text/analytics/v2.1/keyPhrases',\n",
    "    headers={'Ocp-Apim-Subscription-Key': CLE},\n",
    "    json={'documents': [\n",
    "        {'id': '1', 'language': 'fr', 'text': TEXTE1},\n",
    "        {'id': '2', 'language': 'en', 'text': TEXTE2},\n",
    "        {'id': '3', 'language': 'es', 'text': TEXTE3},\n",
    "        {'id': '4', 'language': 'fr', 'text': TEXTE4}\n",
    "    ]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 : brouettes, voile, foule de Chinois, Passepartout, mains, poches, Céleste Empire, Japonais, palanquins, faveur',\n",
       " '2 : heart, bloom, summer world, locust-trees, music, lips, fragrance, blossoms, air, spring, step, song, morning, life',\n",
       " '3 : luna, luz tranquila, alba, resplandor fugaz, viento, murmullo grave, posa, cruz, cantico de paz',\n",
       " '4 : ombre, main, tutelle avare, suites, proie, labyrinthe, vrai chemin, épouvante, crainte, part de la cité, aveuglement, cécité, temps, mal']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ f\"{doc['id']} : {', '.join(doc['keyPhrases'])}\" \n",
    "  for doc in sorted(reponse.json()['documents'], key=lambda doc: doc['id'])\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-language-textanalytics\n",
      "  Downloading azure_cognitiveservices_language_textanalytics-0.2.1-py2.py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting msrest>=0.6.21 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-common~=1.1 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting azure-core<2.0.0,>=1.26.2 (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_core-1.27.1-py3-none-any.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2023.5.7)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in /home/codespace/.local/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.0.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: azure-common, oauthlib, isodate, requests-oauthlib, azure-core, msrest, azure-mgmt-core, azure-cognitiveservices-language-textanalytics\n",
      "Successfully installed azure-cognitiveservices-language-textanalytics-0.2.1 azure-common-1.1.28 azure-core-1.27.1 azure-mgmt-core-1.4.0 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-language-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiTexte = TextAnalyticsClient(SERVEUR, CognitiveServicesCredentials(CLE))\n",
    "\n",
    "reponse = apiTexte.sentiment(documents=[\n",
    "    {'id': '1', 'language': 'fr', 'text': TEXTE1},\n",
    "    {'id': '2', 'language': 'en', 'text': TEXTE2},\n",
    "    {'id': '3', 'language': 'es', 'text': TEXTE3},\n",
    "    {'id': '4', 'language': 'fr', 'text': TEXTE4}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'additional_properties': {},\n",
      "  'id': '2',\n",
      "  'score': 0.9599582552909851,\n",
      "  'statistics': None},\n",
      " {'additional_properties': {},\n",
      "  'id': '1',\n",
      "  'score': 0.7140833735466003,\n",
      "  'statistics': None},\n",
      " {'additional_properties': {},\n",
      "  'id': '3',\n",
      "  'score': 0.6403309106826782,\n",
      "  'statistics': None},\n",
      " {'additional_properties': {},\n",
      "  'id': '4',\n",
      "  'score': 0.3863636255264282,\n",
      "  'statistics': None}]\n"
     ]
    }
   ],
   "source": [
    "pprint([doc.__dict__ for doc in sorted(reponse.documents, key=lambda doc: -doc.score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse = apiTexte.key_phrases(documents=[\n",
    "    {'id': '1', 'language': 'fr', 'text': TEXTE1},\n",
    "    {'id': '2', 'language': 'en', 'text': TEXTE2},\n",
    "    {'id': '3', 'language': 'es', 'text': TEXTE3},\n",
    "    {'id': '4', 'language': 'fr', 'text': TEXTE4}\n",
    "], show_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 : brouettes, voile, foule de Chinois, Passepartout, mains, poches, Céleste Empire, Japonais, palanquins, faveur',\n",
       " '2 : heart, bloom, summer world, locust-trees, music, lips, fragrance, blossoms, air, spring, step, song, morning, life',\n",
       " '3 : luna, luz tranquila, alba, resplandor fugaz, viento, murmullo grave, posa, cruz, cantico de paz',\n",
       " '4 : ombre, main, tutelle avare, suites, proie, labyrinthe, vrai chemin, épouvante, crainte, part de la cité, aveuglement, cécité, temps, mal']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ f\"{doc.id} : {', '.join(doc.key_phrases)}\"\n",
    "  for doc in sorted(reponse.documents, key=lambda doc: doc.id)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
